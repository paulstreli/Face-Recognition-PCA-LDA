{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENSEMBLE LEARNING PCA-LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "FACTS: \n",
    "Number of images in training set: N = 416 \n",
    "Number of Pixels per image: D = 2576 \n",
    "Number of classes: c = 52 \n",
    "-> \n",
    "Sw: rank(Sw)= N-c = 364 -> Mpca <= 364 \n",
    "Sb: rank(Sb)= c-1 = 51 -> Mlda <= 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and testing sets: 80% is training, 20% is testing\n",
    "\n",
    "splittype = 'class'\n",
    "\n",
    "if (splittype == 'whole'):\n",
    "    training = np.loadtxt('split_whole_train.gzip', dtype = 'uint8')\n",
    "    test = np.loadtxt('split_whole_test.gzip', dtype = 'uint8')\n",
    "elif (splittype == 'class'):\n",
    "    training = np.loadtxt('split_class_train.gzip', dtype = 'uint8')\n",
    "    test = np.loadtxt('split_class_test.gzip', dtype = 'uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "TRAIN_RATIO = 0.8\n",
    "CLASS_SIZE = 52 # number of classes\n",
    "PIC_DIM = (46,56) # dimensions of picture\n",
    "PIC_SIZE = PIC_DIM[0]*PIC_DIM[1]\n",
    "TRAIN_SIZE = training.shape[0]\n",
    "TEST_SIZE = test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble constants\n",
    "BAG_IM_SETS_NUM = 4 # number of bootstrapped image datasets\n",
    "BAG_IM_CLASS_SIZE = 8 # number of pictures in each class \n",
    "\n",
    "BAG_CLASS_SETS_NUM = 0 # number of bootstrapped class datasets\n",
    "BAG_CLASS_CLASS_NUM = 30 # number of classes considered for each data set\n",
    "\n",
    "BAG_FEAT_SETS_NUM = 7 # number of bagged feature datasets\n",
    "M0_M1_RATIO = 0.5\n",
    "\n",
    "Kfold = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order training data depending on their class\n",
    "training = training[np.argsort(training[:,-1]),:]\n",
    "\n",
    "# Create a list of sets each with different bagged training data (repeated images)\n",
    "bag_im_sets = []\n",
    "for s in range(BAG_IM_SETS_NUM):\n",
    "    set_t = np.zeros((CLASS_SIZE*BAG_IM_CLASS_SIZE,PIC_SIZE+1),dtype = 'uint8')\n",
    "    for i in range(CLASS_SIZE):\n",
    "        class_im_t = training[i==(training[:,-1]-1),:]\n",
    "        np.random.shuffle(class_im_t)\n",
    "        set_t[i*BAG_IM_CLASS_SIZE:(i*BAG_IM_CLASS_SIZE)+BAG_IM_CLASS_SIZE,:]=class_im_t[np.random.randint(0,8,size=BAG_IM_CLASS_SIZE),:]\n",
    "    bag_im_sets.append(set_t)\n",
    "    \n",
    "\n",
    "# Create a list of sets each with different bagged training data (selected classes)\n",
    "bag_class_sets = []\n",
    "for s in range(BAG_CLASS_SETS_NUM):\n",
    "    set_t = np.zeros((BAG_CLASS_CLASS_NUM*8,PIC_SIZE+1),dtype = 'uint8')\n",
    "    index_row = 0\n",
    "    for i in random.sample(range(52),BAG_CLASS_CLASS_NUM):\n",
    "        class_im_t = training[i==(training[:,-1]-1),:]\n",
    "        np.random.shuffle(class_im_t)\n",
    "        set_t[index_row:index_row+8,:]=class_im_t\n",
    "        index_row = index_row+8\n",
    "    bag_class_sets.append(set_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Wopt(PCA, LDA, training):\n",
    "    # Order training data depending on their class\n",
    "    training = training[np.argsort(training[:,-1]),:]\n",
    "\n",
    "    # Create a list of arrays depending on the classes\n",
    "    class_sets = []\n",
    "    for i in range(CLASS_SIZE):\n",
    "        class_sets.append(training[i==(training[:,-1]-1),:PIC_SIZE]) # dimensions: numbers of pictures in each class x PIC_SIZE\n",
    "\n",
    "    # Calculate the mean vector of each class\n",
    "    class_means = np.zeros((CLASS_SIZE,PIC_SIZE))\n",
    "    for i in range(CLASS_SIZE):\n",
    "        class_means[i,:] = np.mean(class_sets[i], axis=0)\n",
    "\n",
    "    # Calculate the global mean\n",
    "    global_mean = np.mean(training[:,:PIC_SIZE], axis=0)\n",
    "    \n",
    "    # Compute Sb\n",
    "    class_means_norm = class_means - global_mean # make use of broadcasting\n",
    "    Sb = np.dot(class_means_norm.T, class_means_norm)\n",
    "    \n",
    "    # Compute x-mi\n",
    "    class_sets_norm = []\n",
    "    for i in range(CLASS_SIZE):\n",
    "        class_sets_norm.append(class_sets[i]-class_means[i,:])\n",
    "\n",
    "    # Compute Sw\n",
    "    Sw = np.zeros((PIC_SIZE,PIC_SIZE))\n",
    "    for c in class_sets_norm:\n",
    "        Sw += np.dot(c.T,c)\n",
    "    \n",
    "    train_pic = training [:, :PIC_SIZE]\n",
    "    train_pic_norm = train_pic - global_mean\n",
    "    St = np.dot(train_pic_norm, train_pic_norm.T)\n",
    "    \n",
    "    # Compute Wpca\n",
    "    # Find the eigenvalues of the St matrix\n",
    "    eigvals_St, eigvecs_St = np.linalg.eig(St)\n",
    "\n",
    "    # Take the real part of the eigenvalues (complex eigenvalues are the result of numerical rounding errors)\n",
    "    eigvals_St = np.real(eigvals_St)\n",
    "    # Take the real part and calculate the eigenvectors of the matrix A*A_T\n",
    "    eigvecs_St = train_pic_norm.T.dot(np.real(eigvecs_St))\n",
    "    eigvecs_St = eigvecs_St / np.linalg.norm(eigvecs_St,axis=0)\n",
    "\n",
    "    # Order eigenvectors and eigenvalues according to their size\n",
    "    index_St = (abs(eigvals_St)).argsort()[::-1]\n",
    "    eigvals_St = eigvals_St[index_St]\n",
    "    eigvecs_St = eigvecs_St[:,index_St]\n",
    "    \n",
    "    # Take the best PCA eigenvalues of St for computing Wpca_t\n",
    "    eigvecs_St_best_t = eigvecs_St[:, :PCA]\n",
    "    eigvals_St_best_t = eigvals_St[:PCA]\n",
    "\n",
    "    #Define Wpca_t\n",
    "    Wpca_t = eigvecs_St_best_t\n",
    "    \n",
    "    # Compute inverse of Sw_reduced times Sb_reduced\n",
    "    LDA_inverse_t = np.linalg.inv(Wpca_t.T.dot(Sw).dot(Wpca_t)).dot(Wpca_t.T.dot(Sb).dot(Wpca_t))\n",
    "\n",
    "    # Compute Wlda\n",
    "    # Get the generalised eigenvectors of LDA_matrix with largest LDA eigenvalues\n",
    "    eigvals_LDA_t, eigvecs_LDA_t = np.linalg.eig(LDA_inverse_t)\n",
    "\n",
    "    # Take real part of the eigenvalues (complex eigenvalues are the result of numerical rounding errors)\n",
    "    eigvals_LDA_t = np.real(eigvals_LDA_t)\n",
    "    eigvecs_LDA_t = np.real(eigvecs_LDA_t)\n",
    "\n",
    "    # Order eigenvectors and eigenvalues according to their size\n",
    "    index_LDA_t = (abs(eigvals_LDA_t)).argsort()[::-1]\n",
    "    eigvals_LDA_t = eigvals_LDA_t[index_LDA_t]\n",
    "    eigvecs_LDA_t = eigvecs_LDA_t[:,index_LDA_t]\n",
    "\n",
    "    # We just keep the first LDA eigenvectors and eigenvalues\n",
    "    eigvecs_LDA_best_t = eigvecs_LDA_t[:, :LDA]\n",
    "    eigvals_LDA_best_t = eigvals_LDA_t[:LDA]\n",
    "\n",
    "    # Define Wlda\n",
    "    Wlda_t = eigvecs_LDA_best_t\n",
    "    \n",
    "    Wopt_transposed_t = Wlda_t.T.dot(Wpca_t.T)\n",
    "    return Wopt_transposed_t.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Wopt_bag_class(PCA, LDA, training):\n",
    "    # Order training data depending on their class\n",
    "    training = training[np.argsort(training[:,-1]),:]\n",
    "    \n",
    "    class_size = int(training.shape[0]/8) #number of classes in the training set\n",
    "    class_values = training[np.arange(0,training.shape[0],8),-1]\n",
    "\n",
    "    # Create a list of arrays depending on the classes\n",
    "    class_sets = []\n",
    "    for i in range(class_size):\n",
    "        class_sets.append(training[class_values[i]==training[:,-1],:PIC_SIZE]) # dimensions: numbers of pictures in each class x PIC_SIZE\n",
    "\n",
    "    # Calculate the mean vector of each class\n",
    "    class_means = np.zeros((class_size,PIC_SIZE))\n",
    "    for i in range(class_size):\n",
    "        class_means[i,:] = np.mean(class_sets[i], axis=0)\n",
    "\n",
    "    # Calculate the global mean\n",
    "    global_mean = np.mean(training[:,:PIC_SIZE], axis=0)\n",
    "    \n",
    "    # Compute Sb\n",
    "    class_means_norm = class_means - global_mean # make use of broadcasting\n",
    "    Sb = np.dot(class_means_norm.T, class_means_norm)\n",
    "    \n",
    "    # Compute x-mi\n",
    "    class_sets_norm = []\n",
    "    for i in range(class_size):\n",
    "        class_sets_norm.append(class_sets[i]-class_means[i,:])\n",
    "\n",
    "    # Compute Sw\n",
    "    Sw = np.zeros((PIC_SIZE,PIC_SIZE))\n",
    "    for c in class_sets_norm:\n",
    "        Sw += np.dot(c.T,c)\n",
    "    \n",
    "    train_pic = training [:, :PIC_SIZE]\n",
    "    train_pic_norm = train_pic - global_mean\n",
    "    St = np.dot(train_pic_norm, train_pic_norm.T)\n",
    "    \n",
    "    # Compute Wpca\n",
    "    # Find the eigenvalues of the St matrix\n",
    "    eigvals_St, eigvecs_St = np.linalg.eig(St)\n",
    "\n",
    "    # Take the real part of the eigenvalues (complex eigenvalues are the result of numerical rounding errors)\n",
    "    eigvals_St = np.real(eigvals_St)\n",
    "    # Take the real part and calculate the eigenvectors of the matrix A*A_T\n",
    "    eigvecs_St = train_pic_norm.T.dot(np.real(eigvecs_St))\n",
    "    eigvecs_St = eigvecs_St / np.linalg.norm(eigvecs_St,axis=0)\n",
    "\n",
    "    # Order eigenvectors and eigenvalues according to their size\n",
    "    index_St = (abs(eigvals_St)).argsort()[::-1]\n",
    "    eigvals_St = eigvals_St[index_St]\n",
    "    eigvecs_St = eigvecs_St[:,index_St]\n",
    "    \n",
    "    # Take the best PCA eigenvalues of St for computing Wpca_t\n",
    "    eigvecs_St_best_t = eigvecs_St[:, :PCA]\n",
    "    eigvals_St_best_t = eigvals_St[:PCA]\n",
    "\n",
    "    #Define Wpca_t\n",
    "    Wpca_t = eigvecs_St_best_t\n",
    "    \n",
    "    # Compute inverse of Sw_reduced times Sb_reduced\n",
    "    LDA_inverse_t = np.linalg.inv(Wpca_t.T.dot(Sw).dot(Wpca_t)).dot(Wpca_t.T.dot(Sb).dot(Wpca_t))\n",
    "\n",
    "    # Compute Wlda\n",
    "    # Get the generalised eigenvectors of LDA_matrix with largest LDA eigenvalues\n",
    "    eigvals_LDA_t, eigvecs_LDA_t = np.linalg.eig(LDA_inverse_t)\n",
    "\n",
    "    # Take real part of the eigenvalues (complex eigenvalues are the result of numerical rounding errors)\n",
    "    eigvals_LDA_t = np.real(eigvals_LDA_t)\n",
    "    eigvecs_LDA_t = np.real(eigvecs_LDA_t)\n",
    "\n",
    "    # Order eigenvectors and eigenvalues according to their size\n",
    "    index_LDA_t = (abs(eigvals_LDA_t)).argsort()[::-1]\n",
    "    eigvals_LDA_t = eigvals_LDA_t[index_LDA_t]\n",
    "    eigvecs_LDA_t = eigvecs_LDA_t[:,index_LDA_t]\n",
    "\n",
    "    # We just keep the first LDA eigenvectors and eigenvalues\n",
    "    eigvecs_LDA_best_t = eigvecs_LDA_t[:, :LDA]\n",
    "    eigvals_LDA_best_t = eigvals_LDA_t[:LDA]\n",
    "\n",
    "    # Define Wlda\n",
    "    Wlda_t = eigvecs_LDA_best_t\n",
    "    \n",
    "    Wopt_transposed_t = Wlda_t.T.dot(Wpca_t.T)\n",
    "    return Wopt_transposed_t.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Do_PCA_LDA_KNN(Wopt_t, LDA, K, training):\n",
    "    # Calculate the global mean\n",
    "    global_mean = np.mean(training[:,:PIC_SIZE], axis=0)\n",
    "    \n",
    "    train_pic = training [:, :PIC_SIZE]\n",
    "    train_pic_norm = train_pic - global_mean\n",
    "    \n",
    "    #Project training data into LDA space\n",
    "    train_LDA_t = Wopt_t.T.dot(train_pic_norm.T) # each picture is represented by a column\n",
    "\n",
    "    #Project test data into LDA space\n",
    "    test_norm_t = (test[:,:PIC_SIZE] - global_mean)\n",
    "    test_LDA_t = Wopt_t.T.dot(test_norm_t.T) #each picture is represented by a column\n",
    "    \n",
    "    coord_train_t = []\n",
    "    for point in range(training.shape[0]):\n",
    "        coord_train_t.append(train_LDA_t[:,point])\n",
    "    \n",
    "\n",
    "    coord_test_t = []\n",
    "    for point in range(TEST_SIZE):\n",
    "        coord_test_t.append(test_LDA_t[:,point])\n",
    "\n",
    "    neigh = KNeighborsClassifier(n_neighbors=K)\n",
    "    neigh.fit(coord_train_t,training[:,PIC_SIZE])\n",
    "\n",
    "    classes_predict_k_nn_t = neigh.predict(coord_test_t)\n",
    "    classes_act_NN = test[:,PIC_SIZE]\n",
    "\n",
    "    return np.sum(classes_act_NN==classes_predict_k_nn_t) / classes_predict_k_nn_t.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Do_PCA_LDA_KNN_return_prob(Wopt_t, LDA, K, training):\n",
    "    # Calculate the global mean\n",
    "    global_mean = np.mean(training[:,:PIC_SIZE], axis=0)\n",
    "    \n",
    "    train_pic = training [:, :PIC_SIZE]\n",
    "    train_pic_norm = train_pic - global_mean\n",
    "    \n",
    "    #Project training data into LDA space\n",
    "    train_LDA_t = Wopt_t.T.dot(train_pic_norm.T) # each picture is represented by a column\n",
    "\n",
    "    #Project test data into LDA space\n",
    "    test_norm_t = (test[:,:PIC_SIZE] - global_mean)\n",
    "    test_LDA_t = Wopt_t.T.dot(test_norm_t.T) #each picture is represented by a column\n",
    "    \n",
    "    coord_train_t = []\n",
    "    for point in range(training.shape[0]):\n",
    "        coord_train_t.append(train_LDA_t[:,point])\n",
    "    \n",
    "\n",
    "    coord_test_t = []\n",
    "    for point in range(TEST_SIZE):\n",
    "        coord_test_t.append(test_LDA_t[:,point])\n",
    "\n",
    "    neigh = KNeighborsClassifier(n_neighbors=K)\n",
    "    neigh.fit(coord_train_t,training[:,PIC_SIZE])\n",
    "\n",
    "    return neigh.predict_proba(coord_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Do_PCA_LDA_KNN_return_pred(Wopt_t, LDA, K, training):\n",
    "    # Calculate the global mean\n",
    "    global_mean = np.mean(training[:,:PIC_SIZE], axis=0)\n",
    "    \n",
    "    train_pic = training [:, :PIC_SIZE]\n",
    "    train_pic_norm = train_pic - global_mean\n",
    "    \n",
    "    #Project training data into LDA space\n",
    "    train_LDA_t = Wopt_t.T.dot(train_pic_norm.T) # each picture is represented by a column\n",
    "\n",
    "    #Project test data into LDA space\n",
    "    test_norm_t = (test[:,:PIC_SIZE] - global_mean)\n",
    "    test_LDA_t = Wopt_t.T.dot(test_norm_t.T) #each picture is represented by a column\n",
    "    \n",
    "    coord_train_t = []\n",
    "    for point in range(training.shape[0]):\n",
    "        coord_train_t.append(train_LDA_t[:,point])\n",
    "    \n",
    "\n",
    "    coord_test_t = []\n",
    "    for point in range(TEST_SIZE):\n",
    "        coord_test_t.append(test_LDA_t[:,point])\n",
    "\n",
    "    neigh = KNeighborsClassifier(n_neighbors=K)\n",
    "    neigh.fit(coord_train_t,training[:,PIC_SIZE])\n",
    "\n",
    "    return neigh.predict(coord_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Do_PCA_LDA_SVM_return_pred(Wopt_t, LDA, training):\n",
    "    # Calculate the global mean\n",
    "    global_mean = np.mean(training[:,:PIC_SIZE], axis=0)\n",
    "    \n",
    "    train_pic = training [:, :PIC_SIZE]\n",
    "    train_pic_norm = train_pic - global_mean\n",
    "    \n",
    "    #Project training data into LDA space\n",
    "    train_LDA_t = Wopt_t.T.dot(train_pic_norm.T) # each picture is represented by a column\n",
    "\n",
    "    #Project test data into LDA space\n",
    "    test_norm_t = (test[:,:PIC_SIZE] - global_mean)\n",
    "    test_LDA_t = Wopt_t.T.dot(test_norm_t.T) #each picture is represented by a column\n",
    "    \n",
    "    coord_train_t = []\n",
    "    for point in range(training.shape[0]):\n",
    "        coord_train_t.append(train_LDA_t[:,point])\n",
    "    \n",
    "\n",
    "    coord_test_t = []\n",
    "    for point in range(TEST_SIZE):\n",
    "        coord_test_t.append(test_LDA_t[:,point])\n",
    "\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(np.array(coord_train_t), training[:,PIC_SIZE])\n",
    "\n",
    "    return clf.predict(coord_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Do_PCA_LDA_NC(Wopt_t, LDA,training):\n",
    "    class_size = int(training.shape[0]/8) #number of classes in the training set\n",
    "    class_values = training[np.arange(0,training.shape[0],8),-1]\n",
    "\n",
    "    # Create a list of arrays depending on the classes\n",
    "    class_sets = []\n",
    "    for i in range(class_size):\n",
    "        class_sets.append(training[class_values[i]==training[:,-1],:PIC_SIZE]) # dimensions: numbers of pictures in each class x PIC_SIZE\n",
    "\n",
    "    # Calculate the mean vector of each class\n",
    "    class_means = np.zeros((class_size,PIC_SIZE))\n",
    "    for i in range(class_size):\n",
    "        class_means[i,:] = np.mean(class_sets[i], axis=0)\n",
    "\n",
    "    # Calculate the global mean\n",
    "    global_mean = np.mean(training[:,:PIC_SIZE], axis=0)\n",
    "    \n",
    "    # Compute Sb\n",
    "    class_means_norm = class_means - global_mean # make use of broadcasting\n",
    "    \n",
    "    \n",
    "    #Project training data into LDA space\n",
    "    train_LDA_t = Wopt_t.T.dot(class_means_norm.T) # each picture is represented by a column\n",
    "\n",
    "    #Project test data into LDA space\n",
    "    test_norm_t = (test[:,:PIC_SIZE] - global_mean)\n",
    "    test_LDA_t = Wopt_t.T.dot(test_norm_t.T) #each picture is represented by a column\n",
    "\n",
    "    # Reshape and repeat matrices to allow easier manipulation\n",
    "    train_LDA_reshape_NC_t = np.repeat(train_LDA_t.reshape(LDA,CLASS_SIZE,1),TEST_SIZE, axis=2) #afterwards: axis-0: projected values, axis-1: training pictures, axis-2: repeated values\n",
    "    test_LDA_reshape_NC_t = np.repeat(test_LDA_t.reshape(LDA,1,TEST_SIZE), CLASS_SIZE, axis=1) #afterwards: axis-0: projected values, axis-1: repeated values, axis-2: test pictures\n",
    "\n",
    "    # Compute nearest neighbours\n",
    "    LDA_distances_t = np.linalg.norm(test_LDA_reshape_NC_t-train_LDA_reshape_NC_t, axis=0) # axis-0: training picture, axis-1: test picture\n",
    "\n",
    "    # Determine the nearest classes\n",
    "    classes_pred_NN_t = LDA_distances_t.argmin(axis=0)+1\n",
    "    classes_act_NN = test[:,PIC_SIZE]\n",
    "\n",
    "    # Determine the prediction accuracy\n",
    "    return np.sum(classes_pred_NN_t==classes_act_NN) / classes_act_NN.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Do_PCA_LDA_NC_return_pred(Wopt_t, LDA,training):\n",
    "    class_size = int(training.shape[0]/8) #number of classes in the training set\n",
    "    class_values = training[np.arange(0,training.shape[0],8),-1]\n",
    "\n",
    "    # Create a list of arrays depending on the classes\n",
    "    class_sets = []\n",
    "    for i in range(class_size):\n",
    "        class_sets.append(training[class_values[i]==training[:,-1],:PIC_SIZE]) # dimensions: numbers of pictures in each class x PIC_SIZE\n",
    "\n",
    "    # Calculate the mean vector of each class\n",
    "    class_means = np.zeros((class_size,PIC_SIZE))\n",
    "    for i in range(class_size):\n",
    "        class_means[i,:] = np.mean(class_sets[i], axis=0)\n",
    "\n",
    "    # Calculate the global mean\n",
    "    global_mean = np.mean(training[:,:PIC_SIZE], axis=0)\n",
    "    \n",
    "    # Compute Sb\n",
    "    class_means_norm = class_means - global_mean # make use of broadcasting\n",
    "    \n",
    "    \n",
    "    #Project training data into LDA space\n",
    "    train_LDA_t = Wopt_t.T.dot(class_means_norm.T) # each picture is represented by a column\n",
    "\n",
    "    #Project test data into LDA space\n",
    "    test_norm_t = (test[:,:PIC_SIZE] - global_mean)\n",
    "    test_LDA_t = Wopt_t.T.dot(test_norm_t.T) #each picture is represented by a column\n",
    "\n",
    "    # Reshape and repeat matrices to allow easier manipulation\n",
    "    train_LDA_reshape_NC_t = np.repeat(train_LDA_t.reshape(LDA,CLASS_SIZE,1),TEST_SIZE, axis=2) #afterwards: axis-0: projected values, axis-1: training pictures, axis-2: repeated values\n",
    "    test_LDA_reshape_NC_t = np.repeat(test_LDA_t.reshape(LDA,1,TEST_SIZE), CLASS_SIZE, axis=1) #afterwards: axis-0: projected values, axis-1: repeated values, axis-2: test pictures\n",
    "\n",
    "    # Compute nearest neighbours\n",
    "    LDA_distances_t = np.linalg.norm(test_LDA_reshape_NC_t-train_LDA_reshape_NC_t, axis=0) # axis-0: training picture, axis-1: test picture\n",
    "\n",
    "    # Determine the nearest classes\n",
    "    return LDA_distances_t.argmin(axis=0)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE BAGGING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Wopt_bag_feature(M0, M1, LDA, training):\n",
    "    # Order training data depending on their class\n",
    "    training = training[np.argsort(training[:,-1]),:]\n",
    "    \n",
    "    class_size = int(training.shape[0]/8) #number of classes in the training set\n",
    "    class_values = training[np.arange(0,training.shape[0],8),-1]\n",
    "\n",
    "    # Create a list of arrays depending on the classes\n",
    "    class_sets = []\n",
    "    for i in range(class_size):\n",
    "        class_sets.append(training[class_values[i]==training[:,-1],:PIC_SIZE]) # dimensions: numbers of pictures in each class x PIC_SIZE\n",
    "\n",
    "    # Calculate the mean vector of each class\n",
    "    class_means = np.zeros((class_size,PIC_SIZE))\n",
    "    for i in range(class_size):\n",
    "        class_means[i,:] = np.mean(class_sets[i], axis=0)\n",
    "\n",
    "    # Calculate the global mean\n",
    "    global_mean = np.mean(training[:,:PIC_SIZE], axis=0)\n",
    "    \n",
    "    # Compute Sb\n",
    "    class_means_norm = class_means - global_mean # make use of broadcasting\n",
    "    Sb = np.dot(class_means_norm.T, class_means_norm)\n",
    "    \n",
    "    # Compute x-mi\n",
    "    class_sets_norm = []\n",
    "    for i in range(class_size):\n",
    "        class_sets_norm.append(class_sets[i]-class_means[i,:])\n",
    "\n",
    "    # Compute Sw\n",
    "    Sw = np.zeros((PIC_SIZE,PIC_SIZE))\n",
    "    for c in class_sets_norm:\n",
    "        Sw += np.dot(c.T,c)\n",
    "    \n",
    "    train_pic = training [:, :PIC_SIZE]\n",
    "    train_pic_norm = train_pic - global_mean\n",
    "    St = np.dot(train_pic_norm, train_pic_norm.T)\n",
    "    \n",
    "    # Compute Wpca\n",
    "    # Find the eigenvalues of the St matrix\n",
    "    eigvals_St, eigvecs_St = np.linalg.eig(St)\n",
    "\n",
    "    # Take the real part of the eigenvalues (complex eigenvalues are the result of numerical rounding errors)\n",
    "    eigvals_St = np.real(eigvals_St)\n",
    "    # Take the real part and calculate the eigenvectors of the matrix A*A_T\n",
    "    eigvecs_St = train_pic_norm.T.dot(np.real(eigvecs_St))\n",
    "    eigvecs_St = eigvecs_St / np.linalg.norm(eigvecs_St,axis=0)\n",
    "\n",
    "    # Order eigenvectors and eigenvalues according to their size\n",
    "    index_St = (abs(eigvals_St)).argsort()[::-1]\n",
    "    eigvals_St = eigvals_St[index_St]\n",
    "    eigvecs_St = eigvecs_St[:,index_St]\n",
    "    \n",
    "    M0_indices = np.arange(0,M0)\n",
    "    M1_indices = np.array(np.array(random.sample(range(np.unique(training,axis=0).shape[0]-1-M0),M1)))+M0\n",
    "    indices = np.append(M0_indices,M1_indices).astype('uint32')\n",
    "    \n",
    "    # Take the best PCA eigenvalues of St for computing Wpca_t\n",
    "    eigvecs_St_best_t = eigvecs_St[:, indices]\n",
    "    eigvals_St_best_t = eigvals_St[indices]\n",
    "\n",
    "    #Define Wpca_t\n",
    "    Wpca_t = eigvecs_St_best_t\n",
    "    \n",
    "    # Compute inverse of Sw_reduced times Sb_reduced\n",
    "    LDA_inverse_t = np.linalg.inv(Wpca_t.T.dot(Sw).dot(Wpca_t)).dot(Wpca_t.T.dot(Sb).dot(Wpca_t))\n",
    "\n",
    "    # Compute Wlda\n",
    "    # Get the generalised eigenvectors of LDA_matrix with largest LDA eigenvalues\n",
    "    eigvals_LDA_t, eigvecs_LDA_t = np.linalg.eig(LDA_inverse_t)\n",
    "\n",
    "    # Take real part of the eigenvalues (complex eigenvalues are the result of numerical rounding errors)\n",
    "    eigvals_LDA_t = np.real(eigvals_LDA_t)\n",
    "    eigvecs_LDA_t = np.real(eigvecs_LDA_t)\n",
    "\n",
    "    # Order eigenvectors and eigenvalues according to their size\n",
    "    index_LDA_t = (abs(eigvals_LDA_t)).argsort()[::-1]\n",
    "    eigvals_LDA_t = eigvals_LDA_t[index_LDA_t]\n",
    "    eigvecs_LDA_t = eigvecs_LDA_t[:,index_LDA_t]\n",
    "\n",
    "    # We just keep the first LDA eigenvectors and eigenvalues\n",
    "    eigvecs_LDA_best_t = eigvecs_LDA_t[:, :LDA]\n",
    "    eigvals_LDA_best_t = eigvals_LDA_t[:LDA]\n",
    "\n",
    "    # Define Wlda\n",
    "    Wlda_t = eigvecs_LDA_best_t\n",
    "    \n",
    "    Wopt_transposed_t = Wlda_t.T.dot(Wpca_t.T)\n",
    "    return Wopt_transposed_t.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIERARCHY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dict_bag_hier = []\n",
    "for s in bag_class_sets:\n",
    "    Mpca_set = np.array([210])\n",
    "    Mlda_set = np.array(random.sample(range(1,np.unique(s[:,-1]).shape[0]-1),5))\n",
    "    prediction_accuracy = 0\n",
    "    W = 0\n",
    "    Mlda = 0\n",
    "    Mpca = 0\n",
    "    for p in range(Mpca_set.shape[0]):\n",
    "        for l in range(Mlda_set.shape[0]):\n",
    "            if Mlda_set[l]<=Mpca_set[p]:\n",
    "                Wopt_t = Get_Wopt_bag_feature(int(Mpca_set[p]*M0_M1_RATIO),int(Mpca_set[p]*(1-M0_M1_RATIO)),Mlda_set[l],s)\n",
    "                prediction_accuracy_t=Do_PCA_LDA_KNN(Wopt_t,Mlda_set[l],Kfold,s)\n",
    "            else:\n",
    "                Wopt_t = Get_Wopt_bag_feature(int(Mpca_set[p]*M0_M1_RATIO),int(Mpca_set[p]*(1-M0_M1_RATIO)),Mpca_set[p],s)\n",
    "                prediction_accuracy_t=Do_PCA_LDA_KNN(Wopt_t,Mpca_set[p],Kfold,s)\n",
    "            \n",
    "            if prediction_accuracy_t > prediction_accuracy:\n",
    "                prediction_accuracy = prediction_accuracy_t\n",
    "                W = Wopt_t\n",
    "                Mlda = Mlda_set[l]\n",
    "                Mpca = Mpca_set[p]\n",
    "    Dict_bag_hier.append({'Wopt':W,'Mlda':Mlda,'Mpca':Mpca})\n",
    "    print(\"Prediction accuracy\", prediction_accuracy)\n",
    "    print(\"Mlda\", Mlda)\n",
    "    print(\"Mpca\", Mpca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENSEMBLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy 0.7692307692307693\n",
      "Mlda 38\n",
      "Mpca 189\n",
      "Prediction accuracy 0.7211538461538461\n",
      "Mlda 43\n",
      "Mpca 165\n",
      "Prediction accuracy 0.7980769230769231\n",
      "Mlda 30\n",
      "Mpca 137\n",
      "Prediction accuracy 0.7211538461538461\n",
      "Mlda 20\n",
      "Mpca 39\n"
     ]
    }
   ],
   "source": [
    "Dict_bag_im = []\n",
    "for s in bag_im_sets:\n",
    "    Mpca_set = np.array(random.sample(range(1,np.unique(s,axis=0).shape[0]-np.unique(s[:,-1]).shape[0]),5))\n",
    "    Mlda_set = np.array(random.sample(range(1,np.unique(s[:,-1]).shape[0]-1),5))\n",
    "    prediction_accuracy = 0\n",
    "    W = 0\n",
    "    Mlda = 0\n",
    "    Mpca = 0\n",
    "    for p in range(Mpca_set.shape[0]):\n",
    "        for l in range(Mlda_set.shape[0]):\n",
    "            if Mlda_set[l]<=Mpca_set[p]:\n",
    "                Wopt_t = Get_Wopt_bag_class(Mpca_set[p],Mlda_set[l],s)\n",
    "                prediction_accuracy_t=Do_PCA_LDA_KNN(Wopt_t,Mlda_set[l], Kfold, training)\n",
    "            else:\n",
    "                Wopt_t = Get_Wopt_bag_class(Mpca_set[p],Mpca_set[p],s)\n",
    "                prediction_accuracy_t=Do_PCA_LDA_KNN(Wopt_t,Mpca_set[p], Kfold, training)\n",
    "            \n",
    "            if prediction_accuracy_t > prediction_accuracy:\n",
    "                prediction_accuracy = prediction_accuracy_t\n",
    "                W = Wopt_t\n",
    "                Mlda = Mlda_set[l]\n",
    "                Mpca = Mpca_set[p]\n",
    "    Dict_bag_im.append({'Wopt':W,'Mlda':Mlda,'Mpca':Mpca})\n",
    "    print(\"Prediction accuracy\", prediction_accuracy)\n",
    "    print(\"Mlda\", Mlda)\n",
    "    print(\"Mpca\", Mpca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy 0.8269230769230769\n",
      "Mlda 46\n",
      "Mpca 210\n",
      "Prediction accuracy 0.8557692307692307\n",
      "Mlda 24\n",
      "Mpca 210\n",
      "Prediction accuracy 0.8846153846153846\n",
      "Mlda 37\n",
      "Mpca 210\n",
      "Prediction accuracy 0.8557692307692307\n",
      "Mlda 38\n",
      "Mpca 210\n",
      "Prediction accuracy 0.8557692307692307\n",
      "Mlda 45\n",
      "Mpca 210\n",
      "Prediction accuracy 0.875\n",
      "Mlda 43\n",
      "Mpca 210\n",
      "Prediction accuracy 0.8942307692307693\n",
      "Mlda 45\n",
      "Mpca 210\n"
     ]
    }
   ],
   "source": [
    "Dict_bag_feat = []\n",
    "for s in range(BAG_FEAT_SETS_NUM):\n",
    "    Mpca_set = np.array([210])\n",
    "    Mlda_set = np.array(random.sample(range(1,np.unique(training[:,-1]).shape[0]-1),5))\n",
    "    prediction_accuracy = 0\n",
    "    W = 0\n",
    "    Mlda = 0\n",
    "    Mpca = 0\n",
    "    for p in range(Mpca_set.shape[0]):\n",
    "        for l in range(Mlda_set.shape[0]):\n",
    "            if Mlda_set[l]<=Mpca_set[p]:\n",
    "                Wopt_t = Get_Wopt_bag_feature(int(Mpca_set[p]*M0_M1_RATIO),int(Mpca_set[p]*(1-M0_M1_RATIO)),Mlda_set[l],training)\n",
    "                prediction_accuracy_t=Do_PCA_LDA_KNN(Wopt_t,Mlda_set[l], Kfold, training)\n",
    "            else:\n",
    "                Wopt_t = Get_Wopt_bag_feature(int(Mpca_set[p]*M0_M1_RATIO),int(Mpca_set[p]*(1-M0_M1_RATIO)),Mpca_set[p],training)\n",
    "                prediction_accuracy_t=Do_PCA_LDA_KNN(Wopt_t,Mpca_set[p], Kfold, training)\n",
    "            \n",
    "            if prediction_accuracy_t > prediction_accuracy:\n",
    "                prediction_accuracy = prediction_accuracy_t\n",
    "                W = Wopt_t\n",
    "                Mlda = Mlda_set[l]\n",
    "                Mpca = Mpca_set[p]\n",
    "    Dict_bag_feat.append({'Wopt':W,'Mlda':Mlda,'Mpca':Mpca})\n",
    "    print(\"Prediction accuracy\", prediction_accuracy)\n",
    "    print(\"Mlda\", Mlda)\n",
    "    print(\"Mpca\", Mpca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Fusion Majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "Models = Dict_bag_feat + Dict_bag_im\n",
    "Prediction_matrix = np.zeros((len(Models),TEST_SIZE))\n",
    "i_t = 0\n",
    "for m in Models:\n",
    "    Prediction_matrix[i_t,:] = Do_PCA_LDA_KNN_return_pred(m['Wopt'], m['Mlda'], Kfold, training)\n",
    "    i_t = i_t + 1\n",
    "\n",
    "prediction_final = np.zeros((TEST_SIZE,), dtype=int)                                                              \n",
    "for i in range(TEST_SIZE):\n",
    "    counts = np.bincount(Prediction_matrix[:,i].astype('int'))\n",
    "    prediction_final[i] = np.argmax(counts)\n",
    "\n",
    "classes_act = test[:,PIC_SIZE]\n",
    "\n",
    "# Print the corresponding confusion matrix\n",
    "cm_PCA_LDA_ensemble = confusion_matrix(classes_act, prediction_final)\n",
    "\n",
    "plt.matshow(cm_PCA_LDA_ensemble, cmap = 'Blues')\n",
    "plt.colorbar()\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "# Determine the prediction accuracy\n",
    "accuracy_PCA_LDA_NN_ensemble = np.sum(prediction_final==classes_act) / classes_act.shape[0]\n",
    "print(\"Prediction Accuracy:\",accuracy_PCA_LDA_NN_ensemble)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Max Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 0.9134615384615384\n"
     ]
    }
   ],
   "source": [
    "Prediction_matrix_max = np.zeros((len(Models),TEST_SIZE,2))\n",
    "i_t = 0\n",
    "for m in Models:\n",
    "    proba = Do_PCA_LDA_KNN_return_prob(m['Wopt'], m['Mlda'], Kfold, training)\n",
    "    Prediction_matrix_max[i_t,:,0] = np.argmax(proba,axis=1)+1 #class\n",
    "    Prediction_matrix_max[i_t,:,1] = np.amax(proba,axis=1) #probability\n",
    "    i_t = i_t + 1\n",
    "\n",
    "prediction_final_max = np.zeros((TEST_SIZE,), dtype=int)                                                              \n",
    "for i in range(TEST_SIZE):\n",
    "    max_prob_class = np.argmax(Prediction_matrix_max[:,i,1])\n",
    "    prediction_final_max[i] = Prediction_matrix_max[max_prob_class,i,0]\n",
    "\n",
    "classes_act = test[:,PIC_SIZE]\n",
    "# Print the corresponding confusion matrix\n",
    "cm_PCA_LDA_ensemble_max = confusion_matrix(classes_act, prediction_final_max)\n",
    "\n",
    "plt.matshow(cm_PCA_LDA_ensemble_max, cmap = 'Blues')\n",
    "plt.colorbar()\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "# Determine the prediction accuracy\n",
    "accuracy_PCA_LDA_NN_ensemble_max = np.sum(prediction_final_max==classes_act) / classes_act.shape[0]\n",
    "print(\"Prediction Accuracy:\",accuracy_PCA_LDA_NN_ensemble_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Ensemble averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "Prediction_matrix_av = np.zeros((TEST_SIZE,CLASS_SIZE))\n",
    "i_t = 0\n",
    "for m in Models:\n",
    "    proba = Do_PCA_LDA_KNN_return_prob(m['Wopt'], m['Mlda'], Kfold, training)\n",
    "    Prediction_matrix_av = Prediction_matrix_av + proba\n",
    "    \n",
    "Prediction_matrix_av = Prediction_matrix_av/len(m)\n",
    "\n",
    "prediction_final_av = np.argmax(Prediction_matrix_av,axis=1)+1 #class\n",
    "\n",
    "classes_act = test[:,PIC_SIZE]\n",
    "# Print the corresponding confusion matrix\n",
    "cm_PCA_LDA_ensemble_av = confusion_matrix(classes_act, prediction_final_av)\n",
    "\n",
    "plt.matshow(cm_PCA_LDA_ensemble_av, cmap = 'Blues')\n",
    "plt.colorbar()\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "# Determine the prediction accuracy\n",
    "accuracy_PCA_LDA_NN_ensemble_av = np.sum(prediction_final_av==classes_act) / classes_act.shape[0]\n",
    "print(\"Prediction Accuracy:\",accuracy_PCA_LDA_NN_ensemble_av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
